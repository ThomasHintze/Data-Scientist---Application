{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "e2cbe42c26e10d0bffbf8cd5214edc6cf5a71ee44692df5dfb7319ad6ee6ed28"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# **My Implementation - Thomas Hintze**\n",
    "\n",
    "I started off by reading the material and educating myself on the topic. I found a couple other articles, that helped me get a better picture of what distinguishes phishing URLs. \n",
    "\n",
    "## Articles:\n",
    "\n",
    "[Detecting Malicious URLs in E-mail – An Implementation](https://reader.elsevier.com/reader/sd/pii/S2212671613000218?token=EDF32AFC183DB659B6FBD4BDB32CD345633A44F43036B686CBF7186EEA9E1E810042C3619AF67DD148DA2CD679B22098)\n",
    "\n",
    "[Datasets for phishing websites detection](https://www.sciencedirect.com/science/article/pii/S2352340920313202)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Extraction functions\n",
    "\n",
    "I decided to extract a couple of features from the URLs, focusing on symbols and digits, as many of the articles I read descirbed these as typical features of phishing URLs. \n",
    "\n",
    "The first function was a parsing funtion for the URL, so that different parts of the URL can be analyzed separately. Some parts of the URL, such as the top-level domain(tld) and path+query, can more freely be modified, and must therfore more carefully be analyzed. \n",
    "\n",
    "The other two extraction functions are for counting the amount of symbols and digits in the URL. Legit websites tend to have less digits and symbols in their URLs. These basic features could also be used in combination with sub-strings of the URL and the implemented \"parse_url\" function.\n",
    "\n",
    "## Storage\n",
    "I decided to implement storage in the form of nested dictionaries, as they are quick and easy to work with and can easily be converted into other data structures. The main function in this notebook. It test the extraction fucntions(found in the extractors.py file) with a set of real urls(found in the test_urls.py file), visualises one of the features, and finally returns the dictionary of analyzed URLs and their respective features.\n",
    "\n",
    "\n",
    "## Visualisation\n",
    "I decided to use the total number of digits per URL as the feature for the visualisation. I found that around a third of the test URLs, which are verified phishing URLs, contained more than five digits. Some URLs contaied over 20 digits. The visualisation displayed the presence of large amounts of digits in phishing URLs, but further analysis and comparisons, with other metrics, would be needed to ensure and validate a phishing URL.\n",
    "\n",
    "## What could go wrong?\n",
    "There are parts of the code that would need to be improved, for it to be reliable.\n",
    "\n",
    "Firstly, the feature extractors would need to have input verification, to ensure that the right kind of input is given. In this case, I could save the already created, error containing dictionary externally, perhaps as a .csv file. I would then assess the error, fix it, re-run the extraction, and compare it with the original to verify that the error was fixed.\n",
    "\n",
    "Secondly, the extractors could possibly fail to identify crucial information and cause malfunctions in the analysis process. For example, the symbols extractor only contains the ten symbols: \"´\", \"%\", \"#\", \"^\", \"$\", \"&\", \"-\", \"*\", \":\", and \"@\". If a URL containing symbols other than these ten is analyzed, the extractor fails to recognize the symbol, and skips it as if it was a normal letter. This feature would need improvement and development, as more symbols show up. There could be a filter included, that would add the unrecognized symbols to a list called \"others\", that could be viewed and used for development of the extractor."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Here is the main fucntion that is used for the testing. It returns the dictionary with 30 analyzed URLs below, in a dictionary, and visualises the total amounts of digits found in the URLs.\n",
    "Libraries used are \"pandas\" and \"matplotlib\" for visualising."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib\n",
    "import extractors as e, test_urls as t\n",
    "\n",
    "def main(URL_list):\n",
    "    if len(URL_list) == 0:\n",
    "        print(\"Plese input a list of strings.\")     #Simple input verification\n",
    "        return False\n",
    "    else:\n",
    "        dictionary = {}     #Initializes a dictionary for url data to be stored in\n",
    "        data = {}           #Initializes a dictionary to be transformed into a dataframe that can be visualized\n",
    "        i = 0\n",
    "\n",
    "        for url in URL_list:\n",
    "            url_features = {}\n",
    "            url_features = e.parse_url(url)\n",
    "            url_features['digits'] = e.count_digits(url)\n",
    "            url_features['symbols'] = e.count_symbols(url)\n",
    "            dictionary[i] = url_features                    #Adds features to the already initialized dictionary for data storage\n",
    "            tempdata = {}\n",
    "            tempdata['Digits'] = e.count_digits(url)\n",
    "            data[i] = tempdata                              #Adds data on digit amount to dataframe dictionary, for visualisation\n",
    "            i += 1\n",
    "        \n",
    "        df = pd.DataFrame(data)\n",
    "        df = df.transpose()\n",
    "        df = df.sort_values(by='Digits', ascending=False)  #Creates and sorts a dataframe, ready for visualisation\n",
    "\n",
    "        plot1 = df.plot.bar()                              #Decided on barplot, as it visualizes teh feature well\n",
    "        plot1.set_ylim(0, (max(data) + 5))\n",
    "        plot1.set(xlabel = \"URL (Index in dictionary)\", title='Number of digits found in analyzed URLs')\n",
    "        matplotlib.pyplot.show()\n",
    "\n",
    "        return dictionary\n",
    "\n",
    "main(t.urls)        #runs main function using the URL list from test_urls.py\n"
   ]
  }
 ]
}